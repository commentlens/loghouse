// Package parser is generated by gogll. Do not edit.
package parser

import (
	"bytes"
	"fmt"
	"sort"
	"strings"

	"github.com/commentlens/loghouse/api/loki/logql/lexer"
	"github.com/commentlens/loghouse/api/loki/logql/parser/bsr"
	"github.com/commentlens/loghouse/api/loki/logql/parser/slot"
	"github.com/commentlens/loghouse/api/loki/logql/parser/symbols"
	"github.com/commentlens/loghouse/api/loki/logql/token"
)

type parser struct {
	cI int

	R *descriptors
	U *descriptors

	popped   map[poppedNode]bool
	crf      map[clusterNode][]*crfNode
	crfNodes map[crfNode]*crfNode

	lex         *lexer.Lexer
	parseErrors []*Error

	bsrSet *bsr.Set
}

func newParser(l *lexer.Lexer) *parser {
	return &parser{
		cI:     0,
		lex:    l,
		R:      &descriptors{},
		U:      &descriptors{},
		popped: make(map[poppedNode]bool),
		crf: map[clusterNode][]*crfNode{
			{symbols.NT_Query, 0}: {},
		},
		crfNodes:    map[crfNode]*crfNode{},
		bsrSet:      bsr.New(symbols.NT_Query, l),
		parseErrors: nil,
	}
}

// Parse returns the BSR set containing the parse forest.
// If the parse was successfull []*Error is nil
func Parse(l *lexer.Lexer) (*bsr.Set, []*Error) {
	return newParser(l).parse()
}

func (p *parser) parse() (*bsr.Set, []*Error) {
	var L slot.Label
	m, cU := len(p.lex.Tokens)-1, 0
	p.ntAdd(symbols.NT_Query, 0)
	// p.DumpDescriptors()
	for !p.R.empty() {
		L, cU, p.cI = p.R.remove()

		// fmt.Println()
		// fmt.Printf("L:%s, cI:%d, I[p.cI]:%s, cU:%d\n", L, p.cI, p.lex.Tokens[p.cI], cU)
		// p.DumpDescriptors()

		switch L {
		case slot.LabelFilter0R0: // LabelFilter : ∙| NestedLabelKey LabelFilterOp string

			p.bsrSet.Add(slot.LabelFilter0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.LabelFilter0R1) {
				p.parseError(slot.LabelFilter0R1, p.cI, first[slot.LabelFilter0R1])
				break
			}

			p.call(slot.LabelFilter0R2, cU, p.cI)
		case slot.LabelFilter0R2: // LabelFilter : | NestedLabelKey ∙LabelFilterOp string

			if !p.testSelect(slot.LabelFilter0R2) {
				p.parseError(slot.LabelFilter0R2, p.cI, first[slot.LabelFilter0R2])
				break
			}

			p.call(slot.LabelFilter0R3, cU, p.cI)
		case slot.LabelFilter0R3: // LabelFilter : | NestedLabelKey LabelFilterOp ∙string

			if !p.testSelect(slot.LabelFilter0R3) {
				p.parseError(slot.LabelFilter0R3, p.cI, first[slot.LabelFilter0R3])
				break
			}

			p.bsrSet.Add(slot.LabelFilter0R4, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilter) {
				p.rtn(symbols.NT_LabelFilter, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilter0R0, p.cI, followSets[symbols.NT_LabelFilter])
			}
		case slot.LabelFilterOp0R0: // LabelFilterOp : ∙=

			p.bsrSet.Add(slot.LabelFilterOp0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilterOp) {
				p.rtn(symbols.NT_LabelFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilterOp0R0, p.cI, followSets[symbols.NT_LabelFilterOp])
			}
		case slot.LabelFilterOp1R0: // LabelFilterOp : ∙!=

			p.bsrSet.Add(slot.LabelFilterOp1R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilterOp) {
				p.rtn(symbols.NT_LabelFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilterOp1R0, p.cI, followSets[symbols.NT_LabelFilterOp])
			}
		case slot.LabelFilterOp2R0: // LabelFilterOp : ∙=~

			p.bsrSet.Add(slot.LabelFilterOp2R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilterOp) {
				p.rtn(symbols.NT_LabelFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilterOp2R0, p.cI, followSets[symbols.NT_LabelFilterOp])
			}
		case slot.LabelFilterOp3R0: // LabelFilterOp : ∙!~

			p.bsrSet.Add(slot.LabelFilterOp3R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilterOp) {
				p.rtn(symbols.NT_LabelFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilterOp3R0, p.cI, followSets[symbols.NT_LabelFilterOp])
			}
		case slot.LabelFilterOp4R0: // LabelFilterOp : ∙>=

			p.bsrSet.Add(slot.LabelFilterOp4R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilterOp) {
				p.rtn(symbols.NT_LabelFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilterOp4R0, p.cI, followSets[symbols.NT_LabelFilterOp])
			}
		case slot.LabelFilterOp5R0: // LabelFilterOp : ∙>

			p.bsrSet.Add(slot.LabelFilterOp5R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilterOp) {
				p.rtn(symbols.NT_LabelFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilterOp5R0, p.cI, followSets[symbols.NT_LabelFilterOp])
			}
		case slot.LabelFilterOp6R0: // LabelFilterOp : ∙<=

			p.bsrSet.Add(slot.LabelFilterOp6R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilterOp) {
				p.rtn(symbols.NT_LabelFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilterOp6R0, p.cI, followSets[symbols.NT_LabelFilterOp])
			}
		case slot.LabelFilterOp7R0: // LabelFilterOp : ∙<

			p.bsrSet.Add(slot.LabelFilterOp7R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelFilterOp) {
				p.rtn(symbols.NT_LabelFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LabelFilterOp7R0, p.cI, followSets[symbols.NT_LabelFilterOp])
			}
		case slot.LabelKey0R0: // LabelKey : ∙var_name

			p.bsrSet.Add(slot.LabelKey0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LabelKey) {
				p.rtn(symbols.NT_LabelKey, cU, p.cI)
			} else {
				p.parseError(slot.LabelKey0R0, p.cI, followSets[symbols.NT_LabelKey])
			}
		case slot.LineFilter0R0: // LineFilter : ∙LineFilterOp string

			p.call(slot.LineFilter0R1, cU, p.cI)
		case slot.LineFilter0R1: // LineFilter : LineFilterOp ∙string

			if !p.testSelect(slot.LineFilter0R1) {
				p.parseError(slot.LineFilter0R1, p.cI, first[slot.LineFilter0R1])
				break
			}

			p.bsrSet.Add(slot.LineFilter0R2, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LineFilter) {
				p.rtn(symbols.NT_LineFilter, cU, p.cI)
			} else {
				p.parseError(slot.LineFilter0R0, p.cI, followSets[symbols.NT_LineFilter])
			}
		case slot.LineFilterOp0R0: // LineFilterOp : ∙|=

			p.bsrSet.Add(slot.LineFilterOp0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LineFilterOp) {
				p.rtn(symbols.NT_LineFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LineFilterOp0R0, p.cI, followSets[symbols.NT_LineFilterOp])
			}
		case slot.LineFilterOp1R0: // LineFilterOp : ∙!=

			p.bsrSet.Add(slot.LineFilterOp1R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LineFilterOp) {
				p.rtn(symbols.NT_LineFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LineFilterOp1R0, p.cI, followSets[symbols.NT_LineFilterOp])
			}
		case slot.LineFilterOp2R0: // LineFilterOp : ∙|~

			p.bsrSet.Add(slot.LineFilterOp2R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LineFilterOp) {
				p.rtn(symbols.NT_LineFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LineFilterOp2R0, p.cI, followSets[symbols.NT_LineFilterOp])
			}
		case slot.LineFilterOp3R0: // LineFilterOp : ∙!~

			p.bsrSet.Add(slot.LineFilterOp3R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LineFilterOp) {
				p.rtn(symbols.NT_LineFilterOp, cU, p.cI)
			} else {
				p.parseError(slot.LineFilterOp3R0, p.cI, followSets[symbols.NT_LineFilterOp])
			}
		case slot.LogQuery0R0: // LogQuery : ∙LogSelector PipelinesMaybe

			p.call(slot.LogQuery0R1, cU, p.cI)
		case slot.LogQuery0R1: // LogQuery : LogSelector ∙PipelinesMaybe

			if !p.testSelect(slot.LogQuery0R1) {
				p.parseError(slot.LogQuery0R1, p.cI, first[slot.LogQuery0R1])
				break
			}

			p.call(slot.LogQuery0R2, cU, p.cI)
		case slot.LogQuery0R2: // LogQuery : LogSelector PipelinesMaybe ∙

			if p.follow(symbols.NT_LogQuery) {
				p.rtn(symbols.NT_LogQuery, cU, p.cI)
			} else {
				p.parseError(slot.LogQuery0R0, p.cI, followSets[symbols.NT_LogQuery])
			}
		case slot.LogSelector0R0: // LogSelector : ∙{ LogSelectorMembersMaybe }

			p.bsrSet.Add(slot.LogSelector0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.LogSelector0R1) {
				p.parseError(slot.LogSelector0R1, p.cI, first[slot.LogSelector0R1])
				break
			}

			p.call(slot.LogSelector0R2, cU, p.cI)
		case slot.LogSelector0R2: // LogSelector : { LogSelectorMembersMaybe ∙}

			if !p.testSelect(slot.LogSelector0R2) {
				p.parseError(slot.LogSelector0R2, p.cI, first[slot.LogSelector0R2])
				break
			}

			p.bsrSet.Add(slot.LogSelector0R3, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LogSelector) {
				p.rtn(symbols.NT_LogSelector, cU, p.cI)
			} else {
				p.parseError(slot.LogSelector0R0, p.cI, followSets[symbols.NT_LogSelector])
			}
		case slot.LogSelectorMember0R0: // LogSelectorMember : ∙LabelKey LogSelectorOp string

			p.call(slot.LogSelectorMember0R1, cU, p.cI)
		case slot.LogSelectorMember0R1: // LogSelectorMember : LabelKey ∙LogSelectorOp string

			if !p.testSelect(slot.LogSelectorMember0R1) {
				p.parseError(slot.LogSelectorMember0R1, p.cI, first[slot.LogSelectorMember0R1])
				break
			}

			p.call(slot.LogSelectorMember0R2, cU, p.cI)
		case slot.LogSelectorMember0R2: // LogSelectorMember : LabelKey LogSelectorOp ∙string

			if !p.testSelect(slot.LogSelectorMember0R2) {
				p.parseError(slot.LogSelectorMember0R2, p.cI, first[slot.LogSelectorMember0R2])
				break
			}

			p.bsrSet.Add(slot.LogSelectorMember0R3, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LogSelectorMember) {
				p.rtn(symbols.NT_LogSelectorMember, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorMember0R0, p.cI, followSets[symbols.NT_LogSelectorMember])
			}
		case slot.LogSelectorMembers0R0: // LogSelectorMembers : ∙LogSelectorMember

			p.call(slot.LogSelectorMembers0R1, cU, p.cI)
		case slot.LogSelectorMembers0R1: // LogSelectorMembers : LogSelectorMember ∙

			if p.follow(symbols.NT_LogSelectorMembers) {
				p.rtn(symbols.NT_LogSelectorMembers, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorMembers0R0, p.cI, followSets[symbols.NT_LogSelectorMembers])
			}
		case slot.LogSelectorMembers1R0: // LogSelectorMembers : ∙LogSelectorMember , LogSelectorMembers

			p.call(slot.LogSelectorMembers1R1, cU, p.cI)
		case slot.LogSelectorMembers1R1: // LogSelectorMembers : LogSelectorMember ∙, LogSelectorMembers

			if !p.testSelect(slot.LogSelectorMembers1R1) {
				p.parseError(slot.LogSelectorMembers1R1, p.cI, first[slot.LogSelectorMembers1R1])
				break
			}

			p.bsrSet.Add(slot.LogSelectorMembers1R2, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.LogSelectorMembers1R2) {
				p.parseError(slot.LogSelectorMembers1R2, p.cI, first[slot.LogSelectorMembers1R2])
				break
			}

			p.call(slot.LogSelectorMembers1R3, cU, p.cI)
		case slot.LogSelectorMembers1R3: // LogSelectorMembers : LogSelectorMember , LogSelectorMembers ∙

			if p.follow(symbols.NT_LogSelectorMembers) {
				p.rtn(symbols.NT_LogSelectorMembers, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorMembers1R0, p.cI, followSets[symbols.NT_LogSelectorMembers])
			}
		case slot.LogSelectorMembersMaybe0R0: // LogSelectorMembersMaybe : ∙
			p.bsrSet.AddEmpty(slot.LogSelectorMembersMaybe0R0, p.cI)

			if p.follow(symbols.NT_LogSelectorMembersMaybe) {
				p.rtn(symbols.NT_LogSelectorMembersMaybe, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorMembersMaybe0R0, p.cI, followSets[symbols.NT_LogSelectorMembersMaybe])
			}
		case slot.LogSelectorMembersMaybe1R0: // LogSelectorMembersMaybe : ∙LogSelectorMembers

			p.call(slot.LogSelectorMembersMaybe1R1, cU, p.cI)
		case slot.LogSelectorMembersMaybe1R1: // LogSelectorMembersMaybe : LogSelectorMembers ∙

			if p.follow(symbols.NT_LogSelectorMembersMaybe) {
				p.rtn(symbols.NT_LogSelectorMembersMaybe, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorMembersMaybe1R0, p.cI, followSets[symbols.NT_LogSelectorMembersMaybe])
			}
		case slot.LogSelectorOp0R0: // LogSelectorOp : ∙=

			p.bsrSet.Add(slot.LogSelectorOp0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LogSelectorOp) {
				p.rtn(symbols.NT_LogSelectorOp, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorOp0R0, p.cI, followSets[symbols.NT_LogSelectorOp])
			}
		case slot.LogSelectorOp1R0: // LogSelectorOp : ∙!=

			p.bsrSet.Add(slot.LogSelectorOp1R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LogSelectorOp) {
				p.rtn(symbols.NT_LogSelectorOp, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorOp1R0, p.cI, followSets[symbols.NT_LogSelectorOp])
			}
		case slot.LogSelectorOp2R0: // LogSelectorOp : ∙=~

			p.bsrSet.Add(slot.LogSelectorOp2R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LogSelectorOp) {
				p.rtn(symbols.NT_LogSelectorOp, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorOp2R0, p.cI, followSets[symbols.NT_LogSelectorOp])
			}
		case slot.LogSelectorOp3R0: // LogSelectorOp : ∙!~

			p.bsrSet.Add(slot.LogSelectorOp3R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_LogSelectorOp) {
				p.rtn(symbols.NT_LogSelectorOp, cU, p.cI)
			} else {
				p.parseError(slot.LogSelectorOp3R0, p.cI, followSets[symbols.NT_LogSelectorOp])
			}
		case slot.MetricQuery0R0: // MetricQuery : ∙sum by ( level ) ( count_over_time ( LogQuery [ duration ] ) )

			p.bsrSet.Add(slot.MetricQuery0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R1) {
				p.parseError(slot.MetricQuery0R1, p.cI, first[slot.MetricQuery0R1])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R2, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R2) {
				p.parseError(slot.MetricQuery0R2, p.cI, first[slot.MetricQuery0R2])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R3, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R3) {
				p.parseError(slot.MetricQuery0R3, p.cI, first[slot.MetricQuery0R3])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R4, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R4) {
				p.parseError(slot.MetricQuery0R4, p.cI, first[slot.MetricQuery0R4])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R5, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R5) {
				p.parseError(slot.MetricQuery0R5, p.cI, first[slot.MetricQuery0R5])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R6, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R6) {
				p.parseError(slot.MetricQuery0R6, p.cI, first[slot.MetricQuery0R6])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R7, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R7) {
				p.parseError(slot.MetricQuery0R7, p.cI, first[slot.MetricQuery0R7])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R8, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R8) {
				p.parseError(slot.MetricQuery0R8, p.cI, first[slot.MetricQuery0R8])
				break
			}

			p.call(slot.MetricQuery0R9, cU, p.cI)
		case slot.MetricQuery0R9: // MetricQuery : sum by ( level ) ( count_over_time ( LogQuery ∙[ duration ] ) )

			if !p.testSelect(slot.MetricQuery0R9) {
				p.parseError(slot.MetricQuery0R9, p.cI, first[slot.MetricQuery0R9])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R10, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R10) {
				p.parseError(slot.MetricQuery0R10, p.cI, first[slot.MetricQuery0R10])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R11, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R11) {
				p.parseError(slot.MetricQuery0R11, p.cI, first[slot.MetricQuery0R11])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R12, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R12) {
				p.parseError(slot.MetricQuery0R12, p.cI, first[slot.MetricQuery0R12])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R13, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.MetricQuery0R13) {
				p.parseError(slot.MetricQuery0R13, p.cI, first[slot.MetricQuery0R13])
				break
			}

			p.bsrSet.Add(slot.MetricQuery0R14, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_MetricQuery) {
				p.rtn(symbols.NT_MetricQuery, cU, p.cI)
			} else {
				p.parseError(slot.MetricQuery0R0, p.cI, followSets[symbols.NT_MetricQuery])
			}
		case slot.NestedLabelKey0R0: // NestedLabelKey : ∙var_name

			p.bsrSet.Add(slot.NestedLabelKey0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_NestedLabelKey) {
				p.rtn(symbols.NT_NestedLabelKey, cU, p.cI)
			} else {
				p.parseError(slot.NestedLabelKey0R0, p.cI, followSets[symbols.NT_NestedLabelKey])
			}
		case slot.NestedLabelKey1R0: // NestedLabelKey : ∙var_name . NestedLabelKey

			p.bsrSet.Add(slot.NestedLabelKey1R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.NestedLabelKey1R1) {
				p.parseError(slot.NestedLabelKey1R1, p.cI, first[slot.NestedLabelKey1R1])
				break
			}

			p.bsrSet.Add(slot.NestedLabelKey1R2, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.NestedLabelKey1R2) {
				p.parseError(slot.NestedLabelKey1R2, p.cI, first[slot.NestedLabelKey1R2])
				break
			}

			p.call(slot.NestedLabelKey1R3, cU, p.cI)
		case slot.NestedLabelKey1R3: // NestedLabelKey : var_name . NestedLabelKey ∙

			if p.follow(symbols.NT_NestedLabelKey) {
				p.rtn(symbols.NT_NestedLabelKey, cU, p.cI)
			} else {
				p.parseError(slot.NestedLabelKey1R0, p.cI, followSets[symbols.NT_NestedLabelKey])
			}
		case slot.Pipeline0R0: // Pipeline : ∙LineFilter

			p.call(slot.Pipeline0R1, cU, p.cI)
		case slot.Pipeline0R1: // Pipeline : LineFilter ∙

			if p.follow(symbols.NT_Pipeline) {
				p.rtn(symbols.NT_Pipeline, cU, p.cI)
			} else {
				p.parseError(slot.Pipeline0R0, p.cI, followSets[symbols.NT_Pipeline])
			}
		case slot.Pipeline1R0: // Pipeline : ∙LabelFilter

			p.call(slot.Pipeline1R1, cU, p.cI)
		case slot.Pipeline1R1: // Pipeline : LabelFilter ∙

			if p.follow(symbols.NT_Pipeline) {
				p.rtn(symbols.NT_Pipeline, cU, p.cI)
			} else {
				p.parseError(slot.Pipeline1R0, p.cI, followSets[symbols.NT_Pipeline])
			}
		case slot.Pipelines0R0: // Pipelines : ∙Pipeline

			p.call(slot.Pipelines0R1, cU, p.cI)
		case slot.Pipelines0R1: // Pipelines : Pipeline ∙

			if p.follow(symbols.NT_Pipelines) {
				p.rtn(symbols.NT_Pipelines, cU, p.cI)
			} else {
				p.parseError(slot.Pipelines0R0, p.cI, followSets[symbols.NT_Pipelines])
			}
		case slot.Pipelines1R0: // Pipelines : ∙Pipeline Pipelines

			p.call(slot.Pipelines1R1, cU, p.cI)
		case slot.Pipelines1R1: // Pipelines : Pipeline ∙Pipelines

			if !p.testSelect(slot.Pipelines1R1) {
				p.parseError(slot.Pipelines1R1, p.cI, first[slot.Pipelines1R1])
				break
			}

			p.call(slot.Pipelines1R2, cU, p.cI)
		case slot.Pipelines1R2: // Pipelines : Pipeline Pipelines ∙

			if p.follow(symbols.NT_Pipelines) {
				p.rtn(symbols.NT_Pipelines, cU, p.cI)
			} else {
				p.parseError(slot.Pipelines1R0, p.cI, followSets[symbols.NT_Pipelines])
			}
		case slot.PipelinesMaybe0R0: // PipelinesMaybe : ∙
			p.bsrSet.AddEmpty(slot.PipelinesMaybe0R0, p.cI)

			if p.follow(symbols.NT_PipelinesMaybe) {
				p.rtn(symbols.NT_PipelinesMaybe, cU, p.cI)
			} else {
				p.parseError(slot.PipelinesMaybe0R0, p.cI, followSets[symbols.NT_PipelinesMaybe])
			}
		case slot.PipelinesMaybe1R0: // PipelinesMaybe : ∙Pipelines

			p.call(slot.PipelinesMaybe1R1, cU, p.cI)
		case slot.PipelinesMaybe1R1: // PipelinesMaybe : Pipelines ∙

			if p.follow(symbols.NT_PipelinesMaybe) {
				p.rtn(symbols.NT_PipelinesMaybe, cU, p.cI)
			} else {
				p.parseError(slot.PipelinesMaybe1R0, p.cI, followSets[symbols.NT_PipelinesMaybe])
			}
		case slot.Query0R0: // Query : ∙LogQuery

			p.call(slot.Query0R1, cU, p.cI)
		case slot.Query0R1: // Query : LogQuery ∙

			if p.follow(symbols.NT_Query) {
				p.rtn(symbols.NT_Query, cU, p.cI)
			} else {
				p.parseError(slot.Query0R0, p.cI, followSets[symbols.NT_Query])
			}
		case slot.Query1R0: // Query : ∙MetricQuery

			p.call(slot.Query1R1, cU, p.cI)
		case slot.Query1R1: // Query : MetricQuery ∙

			if p.follow(symbols.NT_Query) {
				p.rtn(symbols.NT_Query, cU, p.cI)
			} else {
				p.parseError(slot.Query1R0, p.cI, followSets[symbols.NT_Query])
			}

		default:
			panic("This must not happen")
		}
	}
	if !p.bsrSet.Contain(symbols.NT_Query, 0, m) {
		p.sortParseErrors()
		return nil, p.parseErrors
	}
	return p.bsrSet, nil
}

func (p *parser) ntAdd(nt symbols.NT, j int) {
	// fmt.Printf("p.ntAdd(%s, %d)\n", nt, j)
	failed := true
	expected := map[token.Type]string{}
	for _, l := range slot.GetAlternates(nt) {
		if p.testSelect(l) {
			p.dscAdd(l, j, j)
			failed = false
		} else {
			for k, v := range first[l] {
				expected[k] = v
			}
		}
	}
	if failed {
		for _, l := range slot.GetAlternates(nt) {
			p.parseError(l, j, expected)
		}
	}
}

/*** Call Return Forest ***/

type poppedNode struct {
	X    symbols.NT
	k, j int
}

type clusterNode struct {
	X symbols.NT
	k int
}

type crfNode struct {
	L slot.Label
	i int
}

/*
suppose that L is Y ::=αX ·β
if there is no CRF node labelled (L,i)

	create one let u be the CRF node labelled (L,i)

if there is no CRF node labelled (X, j) {

		create a CRF node v labelled (X, j)
		create an edge from v to u
		ntAdd(X, j)
	} else {

		let v be the CRF node labelled (X, j)
		if there is not an edge from v to u {
			create an edge from v to u
			for all ((X, j,h)∈P) {
				dscAdd(L, i, h);
				bsrAdd(L, i, j, h)
			}
		}
	}
*/
func (p *parser) call(L slot.Label, i, j int) {
	// fmt.Printf("p.call(%s,%d,%d)\n", L,i,j)
	u, exist := p.crfNodes[crfNode{L, i}]
	// fmt.Printf("  u exist=%t\n", exist)
	if !exist {
		u = &crfNode{L, i}
		p.crfNodes[*u] = u
	}
	X := L.Symbols()[L.Pos()-1].(symbols.NT)
	ndV := clusterNode{X, j}
	v, exist := p.crf[ndV]
	if !exist {
		// fmt.Println("  v !exist")
		p.crf[ndV] = []*crfNode{u}
		p.ntAdd(X, j)
	} else {
		// fmt.Println("  v exist")
		if !existEdge(v, u) {
			// fmt.Printf("  !existEdge(%v)\n", u)
			p.crf[ndV] = append(v, u)
			// fmt.Printf("|popped|=%d\n", len(popped))
			for pnd := range p.popped {
				if pnd.X == X && pnd.k == j {
					p.dscAdd(L, i, pnd.j)
					p.bsrSet.Add(L, i, j, pnd.j)
				}
			}
		}
	}
}

func existEdge(nds []*crfNode, nd *crfNode) bool {
	for _, nd1 := range nds {
		if nd1 == nd {
			return true
		}
	}
	return false
}

func (p *parser) rtn(X symbols.NT, k, j int) {
	// fmt.Printf("p.rtn(%s,%d,%d)\n", X,k,j)
	pn := poppedNode{X, k, j}
	if _, exist := p.popped[pn]; !exist {
		p.popped[pn] = true
		for _, nd := range p.crf[clusterNode{X, k}] {
			p.dscAdd(nd.L, nd.i, j)
			p.bsrSet.Add(nd.L, nd.i, k, j)
		}
	}
}

// func CRFString() string {
// 	buf := new(bytes.Buffer)
// 	buf.WriteString("CRF: {")
// 	for cn, nds := range crf{
// 		for _, nd := range nds {
// 			fmt.Fprintf(buf, "%s->%s, ", cn, nd)
// 		}
// 	}
// 	buf.WriteString("}")
// 	return buf.String()
// }

func (cn clusterNode) String() string {
	return fmt.Sprintf("(%s,%d)", cn.X, cn.k)
}

func (n crfNode) String() string {
	return fmt.Sprintf("(%s,%d)", n.L.String(), n.i)
}

// func PoppedString() string {
// 	buf := new(bytes.Buffer)
// 	buf.WriteString("Popped: {")
// 	for p, _ := range popped {
// 		fmt.Fprintf(buf, "(%s,%d,%d) ", p.X, p.k, p.j)
// 	}
// 	buf.WriteString("}")
// 	return buf.String()
// }

/*** descriptors ***/

type descriptors struct {
	set []*descriptor
}

func (ds *descriptors) contain(d *descriptor) bool {
	for _, d1 := range ds.set {
		if d1 == d {
			return true
		}
	}
	return false
}

func (ds *descriptors) empty() bool {
	return len(ds.set) == 0
}

func (ds *descriptors) String() string {
	buf := new(bytes.Buffer)
	buf.WriteString("{")
	for i, d := range ds.set {
		if i > 0 {
			buf.WriteString("; ")
		}
		fmt.Fprintf(buf, "%s", d)
	}
	buf.WriteString("}")
	return buf.String()
}

type descriptor struct {
	L slot.Label
	k int
	i int
}

func (d *descriptor) String() string {
	return fmt.Sprintf("%s,%d,%d", d.L, d.k, d.i)
}

func (p *parser) dscAdd(L slot.Label, k, i int) {
	// fmt.Printf("p.dscAdd(%s,%d,%d)\n", L, k, i)
	d := &descriptor{L, k, i}
	if !p.U.contain(d) {
		p.R.set = append(p.R.set, d)
		p.U.set = append(p.U.set, d)
	}
}

func (ds *descriptors) remove() (L slot.Label, k, i int) {
	d := ds.set[len(ds.set)-1]
	ds.set = ds.set[:len(ds.set)-1]
	// fmt.Printf("remove: %s,%d,%d\n", d.L, d.k, d.i)
	return d.L, d.k, d.i
}

func (p *parser) DumpDescriptors() {
	p.DumpR()
	p.DumpU()
}

func (p *parser) DumpR() {
	fmt.Println("R:")
	for _, d := range p.R.set {
		fmt.Printf(" %s\n", d)
	}
}

func (p *parser) DumpU() {
	fmt.Println("U:")
	for _, d := range p.U.set {
		fmt.Printf(" %s\n", d)
	}
}

/*** TestSelect ***/

func (p *parser) follow(nt symbols.NT) bool {
	_, exist := followSets[nt][p.lex.Tokens[p.cI].Type()]
	return exist
}

func (p *parser) testSelect(l slot.Label) bool {
	_, exist := first[l][p.lex.Tokens[p.cI].Type()]
	// fmt.Printf("testSelect(%s) = %t\n", l, exist)
	return exist
}

var first = []map[token.Type]string{
	// LabelFilter : ∙| NestedLabelKey LabelFilterOp string
	{
		token.T_22: "|",
	},
	// LabelFilter : | ∙NestedLabelKey LabelFilterOp string
	{
		token.T_20: "var_name",
	},
	// LabelFilter : | NestedLabelKey ∙LabelFilterOp string
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_6:  "<",
		token.T_7:  "<=",
		token.T_8:  "=",
		token.T_9:  "=~",
		token.T_10: ">",
		token.T_11: ">=",
	},
	// LabelFilter : | NestedLabelKey LabelFilterOp ∙string
	{
		token.T_18: "string",
	},
	// LabelFilter : | NestedLabelKey LabelFilterOp string ∙
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// LabelFilterOp : ∙=
	{
		token.T_8: "=",
	},
	// LabelFilterOp : = ∙
	{
		token.T_18: "string",
	},
	// LabelFilterOp : ∙!=
	{
		token.T_0: "!=",
	},
	// LabelFilterOp : != ∙
	{
		token.T_18: "string",
	},
	// LabelFilterOp : ∙=~
	{
		token.T_9: "=~",
	},
	// LabelFilterOp : =~ ∙
	{
		token.T_18: "string",
	},
	// LabelFilterOp : ∙!~
	{
		token.T_1: "!~",
	},
	// LabelFilterOp : !~ ∙
	{
		token.T_18: "string",
	},
	// LabelFilterOp : ∙>=
	{
		token.T_11: ">=",
	},
	// LabelFilterOp : >= ∙
	{
		token.T_18: "string",
	},
	// LabelFilterOp : ∙>
	{
		token.T_10: ">",
	},
	// LabelFilterOp : > ∙
	{
		token.T_18: "string",
	},
	// LabelFilterOp : ∙<=
	{
		token.T_7: "<=",
	},
	// LabelFilterOp : <= ∙
	{
		token.T_18: "string",
	},
	// LabelFilterOp : ∙<
	{
		token.T_6: "<",
	},
	// LabelFilterOp : < ∙
	{
		token.T_18: "string",
	},
	// LabelKey : ∙var_name
	{
		token.T_20: "var_name",
	},
	// LabelKey : var_name ∙
	{
		token.T_0: "!=",
		token.T_1: "!~",
		token.T_8: "=",
		token.T_9: "=~",
	},
	// LineFilter : ∙LineFilterOp string
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// LineFilter : LineFilterOp ∙string
	{
		token.T_18: "string",
	},
	// LineFilter : LineFilterOp string ∙
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// LineFilterOp : ∙|=
	{
		token.T_23: "|=",
	},
	// LineFilterOp : |= ∙
	{
		token.T_18: "string",
	},
	// LineFilterOp : ∙!=
	{
		token.T_0: "!=",
	},
	// LineFilterOp : != ∙
	{
		token.T_18: "string",
	},
	// LineFilterOp : ∙|~
	{
		token.T_24: "|~",
	},
	// LineFilterOp : |~ ∙
	{
		token.T_18: "string",
	},
	// LineFilterOp : ∙!~
	{
		token.T_1: "!~",
	},
	// LineFilterOp : !~ ∙
	{
		token.T_18: "string",
	},
	// LogQuery : ∙LogSelector PipelinesMaybe
	{
		token.T_21: "{",
	},
	// LogQuery : LogSelector ∙PipelinesMaybe
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
		token.EOF:  "$",
		token.T_12: "[",
	},
	// LogQuery : LogSelector PipelinesMaybe ∙
	{
		token.EOF:  "$",
		token.T_12: "[",
	},
	// LogSelector : ∙{ LogSelectorMembersMaybe }
	{
		token.T_21: "{",
	},
	// LogSelector : { ∙LogSelectorMembersMaybe }
	{
		token.T_20: "var_name",
		token.T_25: "}",
	},
	// LogSelector : { LogSelectorMembersMaybe ∙}
	{
		token.T_25: "}",
	},
	// LogSelector : { LogSelectorMembersMaybe } ∙
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// LogSelectorMember : ∙LabelKey LogSelectorOp string
	{
		token.T_20: "var_name",
	},
	// LogSelectorMember : LabelKey ∙LogSelectorOp string
	{
		token.T_0: "!=",
		token.T_1: "!~",
		token.T_8: "=",
		token.T_9: "=~",
	},
	// LogSelectorMember : LabelKey LogSelectorOp ∙string
	{
		token.T_18: "string",
	},
	// LogSelectorMember : LabelKey LogSelectorOp string ∙
	{
		token.T_4:  ",",
		token.T_25: "}",
	},
	// LogSelectorMembers : ∙LogSelectorMember
	{
		token.T_20: "var_name",
	},
	// LogSelectorMembers : LogSelectorMember ∙
	{
		token.T_25: "}",
	},
	// LogSelectorMembers : ∙LogSelectorMember , LogSelectorMembers
	{
		token.T_20: "var_name",
	},
	// LogSelectorMembers : LogSelectorMember ∙, LogSelectorMembers
	{
		token.T_4: ",",
	},
	// LogSelectorMembers : LogSelectorMember , ∙LogSelectorMembers
	{
		token.T_20: "var_name",
	},
	// LogSelectorMembers : LogSelectorMember , LogSelectorMembers ∙
	{
		token.T_25: "}",
	},
	// LogSelectorMembersMaybe : ∙
	{
		token.T_25: "}",
	},
	// LogSelectorMembersMaybe : ∙LogSelectorMembers
	{
		token.T_20: "var_name",
	},
	// LogSelectorMembersMaybe : LogSelectorMembers ∙
	{
		token.T_25: "}",
	},
	// LogSelectorOp : ∙=
	{
		token.T_8: "=",
	},
	// LogSelectorOp : = ∙
	{
		token.T_18: "string",
	},
	// LogSelectorOp : ∙!=
	{
		token.T_0: "!=",
	},
	// LogSelectorOp : != ∙
	{
		token.T_18: "string",
	},
	// LogSelectorOp : ∙=~
	{
		token.T_9: "=~",
	},
	// LogSelectorOp : =~ ∙
	{
		token.T_18: "string",
	},
	// LogSelectorOp : ∙!~
	{
		token.T_1: "!~",
	},
	// LogSelectorOp : !~ ∙
	{
		token.T_18: "string",
	},
	// MetricQuery : ∙sum by ( level ) ( count_over_time ( LogQuery [ duration ] ) )
	{
		token.T_19: "sum",
	},
	// MetricQuery : sum ∙by ( level ) ( count_over_time ( LogQuery [ duration ] ) )
	{
		token.T_14: "by",
	},
	// MetricQuery : sum by ∙( level ) ( count_over_time ( LogQuery [ duration ] ) )
	{
		token.T_2: "(",
	},
	// MetricQuery : sum by ( ∙level ) ( count_over_time ( LogQuery [ duration ] ) )
	{
		token.T_17: "level",
	},
	// MetricQuery : sum by ( level ∙) ( count_over_time ( LogQuery [ duration ] ) )
	{
		token.T_3: ")",
	},
	// MetricQuery : sum by ( level ) ∙( count_over_time ( LogQuery [ duration ] ) )
	{
		token.T_2: "(",
	},
	// MetricQuery : sum by ( level ) ( ∙count_over_time ( LogQuery [ duration ] ) )
	{
		token.T_15: "count_over_time",
	},
	// MetricQuery : sum by ( level ) ( count_over_time ∙( LogQuery [ duration ] ) )
	{
		token.T_2: "(",
	},
	// MetricQuery : sum by ( level ) ( count_over_time ( ∙LogQuery [ duration ] ) )
	{
		token.T_21: "{",
	},
	// MetricQuery : sum by ( level ) ( count_over_time ( LogQuery ∙[ duration ] ) )
	{
		token.T_12: "[",
	},
	// MetricQuery : sum by ( level ) ( count_over_time ( LogQuery [ ∙duration ] ) )
	{
		token.T_16: "duration",
	},
	// MetricQuery : sum by ( level ) ( count_over_time ( LogQuery [ duration ∙] ) )
	{
		token.T_13: "]",
	},
	// MetricQuery : sum by ( level ) ( count_over_time ( LogQuery [ duration ] ∙) )
	{
		token.T_3: ")",
	},
	// MetricQuery : sum by ( level ) ( count_over_time ( LogQuery [ duration ] ) ∙)
	{
		token.T_3: ")",
	},
	// MetricQuery : sum by ( level ) ( count_over_time ( LogQuery [ duration ] ) ) ∙
	{
		token.EOF: "$",
	},
	// NestedLabelKey : ∙var_name
	{
		token.T_20: "var_name",
	},
	// NestedLabelKey : var_name ∙
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_6:  "<",
		token.T_7:  "<=",
		token.T_8:  "=",
		token.T_9:  "=~",
		token.T_10: ">",
		token.T_11: ">=",
	},
	// NestedLabelKey : ∙var_name . NestedLabelKey
	{
		token.T_20: "var_name",
	},
	// NestedLabelKey : var_name ∙. NestedLabelKey
	{
		token.T_5: ".",
	},
	// NestedLabelKey : var_name . ∙NestedLabelKey
	{
		token.T_20: "var_name",
	},
	// NestedLabelKey : var_name . NestedLabelKey ∙
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_6:  "<",
		token.T_7:  "<=",
		token.T_8:  "=",
		token.T_9:  "=~",
		token.T_10: ">",
		token.T_11: ">=",
	},
	// Pipeline : ∙LineFilter
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// Pipeline : LineFilter ∙
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// Pipeline : ∙LabelFilter
	{
		token.T_22: "|",
	},
	// Pipeline : LabelFilter ∙
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// Pipelines : ∙Pipeline
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// Pipelines : Pipeline ∙
	{
		token.EOF:  "$",
		token.T_12: "[",
	},
	// Pipelines : ∙Pipeline Pipelines
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// Pipelines : Pipeline ∙Pipelines
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// Pipelines : Pipeline Pipelines ∙
	{
		token.EOF:  "$",
		token.T_12: "[",
	},
	// PipelinesMaybe : ∙
	{
		token.EOF:  "$",
		token.T_12: "[",
	},
	// PipelinesMaybe : ∙Pipelines
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// PipelinesMaybe : Pipelines ∙
	{
		token.EOF:  "$",
		token.T_12: "[",
	},
	// Query : ∙LogQuery
	{
		token.T_21: "{",
	},
	// Query : LogQuery ∙
	{
		token.EOF: "$",
	},
	// Query : ∙MetricQuery
	{
		token.T_19: "sum",
	},
	// Query : MetricQuery ∙
	{
		token.EOF: "$",
	},
}

var followSets = []map[token.Type]string{
	// LabelFilter
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// LabelFilterOp
	{
		token.T_18: "string",
	},
	// LabelKey
	{
		token.T_0: "!=",
		token.T_1: "!~",
		token.T_8: "=",
		token.T_9: "=~",
	},
	// LineFilter
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// LineFilterOp
	{
		token.T_18: "string",
	},
	// LogQuery
	{
		token.EOF:  "$",
		token.T_12: "[",
	},
	// LogSelector
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// LogSelectorMember
	{
		token.T_4:  ",",
		token.T_25: "}",
	},
	// LogSelectorMembers
	{
		token.T_25: "}",
	},
	// LogSelectorMembersMaybe
	{
		token.T_25: "}",
	},
	// LogSelectorOp
	{
		token.T_18: "string",
	},
	// MetricQuery
	{
		token.EOF: "$",
	},
	// NestedLabelKey
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.T_6:  "<",
		token.T_7:  "<=",
		token.T_8:  "=",
		token.T_9:  "=~",
		token.T_10: ">",
		token.T_11: ">=",
	},
	// Pipeline
	{
		token.T_0:  "!=",
		token.T_1:  "!~",
		token.EOF:  "$",
		token.T_12: "[",
		token.T_22: "|",
		token.T_23: "|=",
		token.T_24: "|~",
	},
	// Pipelines
	{
		token.EOF:  "$",
		token.T_12: "[",
	},
	// PipelinesMaybe
	{
		token.EOF:  "$",
		token.T_12: "[",
	},
	// Query
	{
		token.EOF: "$",
	},
}

/*** Errors ***/

/*
Error is returned by Parse at every point at which the parser fails to parse
a grammar production. For non-LL-1 grammars there will be an error for each
alternate attempted by the parser.

The errors are sorted in descending order of input position (index of token in
the stream of tokens).

Normally the error of interest is the one that has parsed the largest number of
tokens.
*/
type Error struct {
	// Index of token that caused the error.
	cI int

	// Grammar slot at which the error occured.
	Slot slot.Label

	// The token at which the error occurred.
	Token *token.Token

	// The line and column in the input text at which the error occurred
	Line, Column int

	// The tokens expected at the point where the error occurred
	Expected map[token.Type]string
}

func (pe *Error) String() string {
	w := new(bytes.Buffer)
	fmt.Fprintf(w, "Parse Error: %s I[%d]=%s at line %d col %d\n",
		pe.Slot, pe.cI, pe.Token, pe.Line, pe.Column)
	exp := []string{}
	for _, e := range pe.Expected {
		exp = append(exp, e)
	}
	fmt.Fprintf(w, "Expected one of: [%s]", strings.Join(exp, ","))
	return w.String()
}

func (p *parser) parseError(slot slot.Label, i int, expected map[token.Type]string) {
	pe := &Error{cI: i, Slot: slot, Token: p.lex.Tokens[i], Expected: expected}
	p.parseErrors = append(p.parseErrors, pe)
}

func (p *parser) sortParseErrors() {
	sort.Slice(p.parseErrors,
		func(i, j int) bool {
			return p.parseErrors[j].Token.Lext() < p.parseErrors[i].Token.Lext()
		})
	for _, pe := range p.parseErrors {
		pe.Line, pe.Column = p.lex.GetLineColumn(pe.Token.Lext())
	}
}
